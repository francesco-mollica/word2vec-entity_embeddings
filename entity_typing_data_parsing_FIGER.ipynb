{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "entity_typing_data_parsing_FIGER.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKL7Wwcj3pSj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6b65c13-bd93-4945-8f2e-3c02e24a628f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "root_dir = \"/content/drive/MyDrive/\"\n",
        "base_dir = root_dir + \"tesi_magistrale/datasets/to_zip/\"\n",
        "path_corpus_data = root_dir + \"tesi_magistrale/datasets/corpus_data_folder/\"\n",
        "figer_path = base_dir + \"FIGER/\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hm6RoPKn3IyB"
      },
      "source": [
        "import json\n",
        "\n",
        "with open(figer_path + \"train.json\", 'r') as inp:\n",
        "    examples_train = [json.loads(l) for l in inp.readlines()]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-66bcSCfxoIo",
        "outputId": "3b6a6444-3e0f-4ecb-c2d1-564952b016bb"
      },
      "source": [
        "print(\"il dataset train contiene \",len(examples_train), \"elementi\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "il dataset train contiene  1505765 elementi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWJkJBNnBsXw"
      },
      "source": [
        "#ci sono 36 frasi che hanno le mentions vuote, le cancello\n",
        "indici = []\n",
        "for i,elem in enumerate(examples_train):\n",
        "  if len(elem['mentions'])==0:\n",
        "     indici.append(i)\n",
        "\n",
        "pop=0\n",
        "for num in indici:\n",
        "  del examples_train[num-pop]\n",
        "  pop+=1"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oT7TBpSx8NI2"
      },
      "source": [
        "#examples_train=examples_train[0:10000]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkDsVLxg5M5k"
      },
      "source": [
        "entire_dataset_list = iter(examples_train)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxEW4AI06Lht"
      },
      "source": [
        "def skip_this_phrase(mentions,dictionary):\n",
        "    prod = 1\n",
        "    for elem in mentions:\n",
        "      prod*=len(elem['labels'])\n",
        "\n",
        "    if prod<=10:\n",
        "      dictionary['minori=_10']+=1\n",
        "    if prod>10 and  prod<=20:\n",
        "      dictionary['maggiori_10_minori=20']+=1\n",
        "    if prod>20 and prod<=50:\n",
        "      dictionary['maggiori_20_minori=50']+=1\n",
        "    if prod>50 and prod<=100:\n",
        "      dictionary['maggiori_50_minori=100']+=1\n",
        "    if prod>100 and prod<=200:\n",
        "      dictionary['maggiori_100_minori=200']+=1\n",
        "    if (prod>200):\n",
        "      dictionary['maggiori_200']+=1\n",
        "    if (prod>20):\n",
        "      return 0\n",
        "    \n",
        "    return prod\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E80h-2ABJl6k",
        "outputId": "ac502e7f-1b9d-4391-8a71-9fa3f9183803"
      },
      "source": [
        "import operator\n",
        "import itertools\n",
        "from tqdm import tqdm\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "\n",
        "lunghezze={\n",
        "    'minori=_10':0,\n",
        "    'maggiori_10_minori=20':0,\n",
        "    'maggiori_20_minori=50':0,\n",
        "    'maggiori_50_minori=100':0,\n",
        "    'maggiori_100_minori=200':0,\n",
        "    'maggiori_200':0,\n",
        "}\n",
        "\n",
        "fp = open(path_corpus_data + 'corpus_data_entire_figer.txt', \"w\")\n",
        "restricted_set = set()\n",
        "#mean=0\n",
        "for num,i in enumerate(tqdm(entire_dataset_list)):\n",
        "  \n",
        "  #calcolo le permutazioni in modo grossolano e skippo le frasi che genererebbero piÃ¹ di 200 permutazioni\n",
        "  perm_priori=skip_this_phrase(i['mentions'],lunghezze)\n",
        "  if (perm_priori==0):\n",
        "    continue\n",
        "  #else:\n",
        "    #print(f\"frase {num}) permutazioni a priori: {prod}\")\n",
        "  #mean+=prod\n",
        "  istance = i['mentions'][:]\n",
        "  if len(istance)>1:\n",
        "    d = sorted(istance, key=operator.itemgetter(\"start\"))\n",
        "    d = {k: list(v) for k, v in itertools.groupby(d, key=operator.itemgetter(\"start\"))}\n",
        "    all_list=[]\n",
        "    for key, value in d.items():\n",
        "      all_list.append(value)\n",
        "\n",
        "    permutations = list(itertools.product(*all_list))\n",
        "    #print(f\"{num}) Permutations: {permutations}\")\n",
        "    iter = 0\n",
        "    real_perm = 0\n",
        "    for p in permutations:\n",
        "          mini_list = []\n",
        "          for lista_labels in p:\n",
        "            mini_list.append(lista_labels['labels'])\n",
        "          \n",
        "          permutations_2 = itertools.product(*mini_list)\n",
        "          real_perm+=len(list(permutations_2))\n",
        "          for p_2 in permutations_2:\n",
        "            phrase = i['tokens'][:]\n",
        "            num_pop=0\n",
        "            for h in range(0, len(p_2)):\n",
        "              start = permutations[iter][h]['start']\n",
        "              end = permutations[iter][h]['end']\n",
        "              phrase[start-num_pop:end-num_pop] = [p_2[h]]\n",
        "              if ((end-start)>1):\n",
        "                num_pop += (end - start) - 1\n",
        "              restricted_set.add(p_2[h])\n",
        "\n",
        "            fp.write((remove_stopwords(' '.join(phrase)) + '\\n'))\n",
        "          iter+=1\n",
        "    if real_perm!=perm_priori:\n",
        "      print(f\"Frase {num}, permutazioni a priori {perm_priori}, permutazioni effettive {real_perm}\")\n",
        "  else:\n",
        "    #print(f\"Una sola mentions, permutazioni effettive {len(istance[0]['labels'])}\")\n",
        "    for k in istance[0]['labels']:\n",
        "      phrase = i['tokens'][:]\n",
        "      if (i['mentions'][0]['end'] - i['mentions'][0]['start'] ==1):          \n",
        "        phrase[i['mentions'][0]['start']] = k\n",
        "        restricted_set.add(k)\n",
        "      else:\n",
        "        phrase[i['mentions'][0]['start']:i['mentions'][0]['end']] = [k]\n",
        "        restricted_set.add(k)\n",
        "\n",
        "      fp.write((remove_stopwords(' '.join(phrase)) + '\\n'))\n",
        "\n",
        "fp.close()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "104216it [00:01, 57549.27it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Frase 95886, permutazioni a priori 1, permutazioni effettive 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "445735it [00:07, 54799.17it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Frase 440055, permutazioni a priori 8, permutazioni effettive 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "562984it [00:09, 58885.82it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Frase 555593, permutazioni a priori 2, permutazioni effettive 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1505729it [00:27, 55316.22it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bIP4-eA30dM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "719bff94-6552-461c-e915-6fdb99b06159"
      },
      "source": [
        "examples_train[5220]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fileid': 'wex/20110513/0/15/149',\n",
              " 'mentions': [{'end': 14,\n",
              "   'labels': ['/person/author', '/person'],\n",
              "   'start': 12},\n",
              "  {'end': 25, 'labels': ['/location/city', '/location'], 'start': 24}],\n",
              " 'senid': 14,\n",
              " 'tokens': ['October',\n",
              "  '-',\n",
              "  'George',\n",
              "  'Stephenson',\n",
              "  \"'s\",\n",
              "  'steam',\n",
              "  'locomotive',\n",
              "  ',',\n",
              "  'The',\n",
              "  'Rocket',\n",
              "  ',',\n",
              "  'defeats',\n",
              "  'John',\n",
              "  'Ericsson',\n",
              "  \"'s\",\n",
              "  'Novelty',\n",
              "  'and',\n",
              "  'thus',\n",
              "  'wins',\n",
              "  'The',\n",
              "  'Rainhill',\n",
              "  'Trials',\n",
              "  'held',\n",
              "  'near',\n",
              "  'Liverpool',\n",
              "  '.']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YU52HrRiQz2E",
        "outputId": "9e02ee0a-de0e-4a49-87b0-04aa4af5c399"
      },
      "source": [
        "lunghezze"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'maggiori_100_minori=200': 0,\n",
              " 'maggiori_10_minori=20': 1,\n",
              " 'maggiori_200': 0,\n",
              " 'maggiori_20_minori=50': 1,\n",
              " 'maggiori_50_minori=100': 0,\n",
              " 'minori=_10': 8}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DXYQpHt_qRe",
        "outputId": "9bed39c6-2e0f-4909-abe4-b864a651c083"
      },
      "source": [
        "print(f\"Frasi skippate {lunghezze['maggiori_200']}, frasi processate {len(examples_train)-lunghezze['maggiori_200']}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frasi skippate 0, frasi processate 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kf58neP0zEGL"
      },
      "source": [
        "restricted_list = list(restricted_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyXqWeAOzBga"
      },
      "source": [
        "import pickle\n",
        "with open(path_corpus_data + 'restricted_list_figer.pkl', 'wb') as fp:\n",
        "  pickle.dump(restricted_list, fp)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}