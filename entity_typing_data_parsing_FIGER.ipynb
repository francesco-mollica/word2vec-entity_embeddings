{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "entity_typing_data_parsing_FIGER.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKL7Wwcj3pSj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b84481a-0f38-4028-bf35-4def25ea0e80"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "root_dir = \"/content/drive/MyDrive/\"\n",
        "base_dir = root_dir + \"tesi_magistrale/datasets/to_zip/\"\n",
        "path_corpus_data = root_dir + \"tesi_magistrale/datasets/corpus_data_folder/\"\n",
        "figer_path = base_dir + \"FIGER/\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hm6RoPKn3IyB"
      },
      "source": [
        "import json\n",
        "\n",
        "with open(figer_path + \"train.json\", 'r') as inp:\n",
        "    examples_train = [json.loads(l) for l in inp.readlines()]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-66bcSCfxoIo",
        "outputId": "57c93d32-819d-4460-ec28-2759e5f93f56"
      },
      "source": [
        "print(\"il dataset train contiene \",len(examples_train), \"elementi\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "il dataset train contiene  1505765 elementi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWJkJBNnBsXw"
      },
      "source": [
        "#ci sono 36 frasi che hanno le mentions vuote, le cancello\n",
        "indici = []\n",
        "for i,elem in enumerate(examples_train):\n",
        "  if len(elem['mentions'])==0:\n",
        "     indici.append(i)\n",
        "\n",
        "pop=0\n",
        "for num in indici:\n",
        "  del examples_train[num-pop]\n",
        "  pop+=1"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkDsVLxg5M5k"
      },
      "source": [
        "entire_dataset_list = iter(examples_train)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4sMvJBQOm9e"
      },
      "source": [
        "lunghezze={\n",
        "    'minori=_10':0,\n",
        "    'maggiori_10_minori=20':0,\n",
        "    'maggiori_20_minori=50':0,\n",
        "    'maggiori_50_minori=100':0,\n",
        "    'maggiori_100_minori=200':0,\n",
        "    'maggiori_200':0,\n",
        "}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E80h-2ABJl6k",
        "outputId": "11f13712-e2a6-43cc-921c-6fcf932088ff"
      },
      "source": [
        "import operator\n",
        "import itertools\n",
        "from tqdm import tqdm\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "\n",
        "fp = open(path_corpus_data + 'corpus_data_entire_figer.txt', \"w\")\n",
        "restricted_set = set()\n",
        "mean=0\n",
        "for num,i in enumerate(tqdm(entire_dataset_list)):\n",
        "  \n",
        "  #calcolo le permutazioni in modo grossolano e skippo le frasi che genererebbero pi√π di 200 permutazioni\n",
        "  prod = 1\n",
        "\n",
        "  for elem in i['mentions']:\n",
        "    prod*=len(elem['labels'])\n",
        "\n",
        "  if prod<=10:\n",
        "    lunghezze['minori=_10']+=1\n",
        "  if prod>10 and  prod<=20:\n",
        "    lunghezze['maggiori_10_minori=20']+=1\n",
        "  if prod>20 and prod<=50:\n",
        "    lunghezze['maggiori_20_minori=50']+=1\n",
        "  if prod>50 and prod<=100:\n",
        "    lunghezze['maggiori_50_minori=100']+=1\n",
        "  if prod>100 and prod<=200:\n",
        "    lunghezze['maggiori_100_minori=200']+=1\n",
        "  if (prod>200):\n",
        "    lunghezze['maggiori_200']+=1\n",
        "    continue\n",
        "\n",
        "  mean+=prod\n",
        "  istance = i['mentions'][:]\n",
        "  if len(istance)>1:\n",
        "    d = sorted(istance, key=operator.itemgetter(\"start\"))\n",
        "    d = {k: list(v) for k, v in itertools.groupby(d, key=operator.itemgetter(\"start\"))}\n",
        "    \n",
        "    all_list=[]\n",
        "    for key, value in d.items():\n",
        "      all_list.append(value)\n",
        "\n",
        "    permutations = list(itertools.product(*all_list))\n",
        "\n",
        "    iter = 0\n",
        "    for p in permutations:\n",
        "          mini_list = []\n",
        "          for lista_labels in p:\n",
        "            mini_list.append(lista_labels['labels'])\n",
        "\n",
        "          permutations_2 = itertools.product(*mini_list)\n",
        "\n",
        "          for p_2 in permutations_2:\n",
        "            phrase = i['tokens'][:]\n",
        "            num_pop=0\n",
        "            for h in range(0, len(p_2)):\n",
        "              start = permutations[iter][h]['start']\n",
        "              end = permutations[iter][h]['end']\n",
        "              phrase[start-num_pop:end-num_pop] = [p_2[h]]\n",
        "              if ((end-start)>1):\n",
        "                num_pop += (end - start) - 1\n",
        "              restricted_set.add(p_2[h])\n",
        "\n",
        "            fp.write((remove_stopwords(' '.join(phrase)) + '\\n'))\n",
        "          iter+=1\n",
        "  else:\n",
        "    for k in istance[0]['labels']:\n",
        "      phrase = i['tokens'][:]\n",
        "      if (i['mentions'][0]['end'] - i['mentions'][0]['start'] ==1):          \n",
        "        phrase[i['mentions'][0]['start']] = k\n",
        "        restricted_set.add(k)\n",
        "      else:\n",
        "        phrase[i['mentions'][0]['start']:i['mentions'][0]['end']] = [k]\n",
        "        restricted_set.add(k)\n",
        "\n",
        "      fp.write((remove_stopwords(' '.join(phrase)) + '\\n'))\n",
        "\n",
        "fp.close()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1505728it [02:30, 10004.02it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bIP4-eA30dM",
        "outputId": "f48e7845-5eb2-4d52-fa23-8210511c34e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "examples_train[0]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fileid': 'wex/20110513/0/0/5',\n",
              " 'mentions': [{'end': 13,\n",
              "   'labels': ['/person/musician', '/person/artist', '/person'],\n",
              "   'start': 11},\n",
              "  {'end': 24,\n",
              "   'labels': ['/person/musician', '/person/artist', '/person'],\n",
              "   'start': 22},\n",
              "  {'end': 29,\n",
              "   'labels': ['/person/musician', '/person/artist', '/person'],\n",
              "   'start': 28}],\n",
              " 'senid': 25,\n",
              " 'tokens': ['The',\n",
              "  'band',\n",
              "  'also',\n",
              "  'shared',\n",
              "  'membership',\n",
              "  'with',\n",
              "  'the',\n",
              "  'similar',\n",
              "  ',',\n",
              "  'defunct',\n",
              "  'group',\n",
              "  'Out',\n",
              "  'Hud',\n",
              "  '(',\n",
              "  'including',\n",
              "  'Tyler',\n",
              "  'Pope',\n",
              "  ',',\n",
              "  'who',\n",
              "  'has',\n",
              "  'played',\n",
              "  'with',\n",
              "  'LCD',\n",
              "  'Soundsystem',\n",
              "  'and',\n",
              "  'written',\n",
              "  'music',\n",
              "  'for',\n",
              "  'Cake',\n",
              "  ')',\n",
              "  '.']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YU52HrRiQz2E",
        "outputId": "851b8d47-92bf-40f6-80cc-1debca209fba"
      },
      "source": [
        "lunghezze"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'maggiori_100_minori=200': 12385,\n",
              " 'maggiori_10_minori=20': 97138,\n",
              " 'maggiori_200': 20574,\n",
              " 'maggiori_20_minori=50': 66261,\n",
              " 'maggiori_50_minori=100': 22441,\n",
              " 'minori=_10': 1286929}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DXYQpHt_qRe",
        "outputId": "a49bc6a1-f0c1-4f5c-de08-e750ff5d434e"
      },
      "source": [
        "print(f\"media permutazioni {mean/len(examples_train)} frasi skippate {lunghezze['maggiori_200']}, frasi processate {len(examples_train)-lunghezze['maggiori_200']}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "media permutazioni 7.282443919191302 frasi skippate 20574, frasi processate 1485155\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kf58neP0zEGL"
      },
      "source": [
        "restricted_list = list(restricted_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyXqWeAOzBga"
      },
      "source": [
        "import pickle\n",
        "with open(path_corpus_data + 'restricted_list_figer.pkl', 'wb') as fp:\n",
        "  pickle.dump(restricted_list, fp)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}