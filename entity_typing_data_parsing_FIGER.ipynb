{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "entity_typing_data_parsing_FIGER.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKL7Wwcj3pSj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2dbfa49-9fc2-4868-cb23-c80c315b72dc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "root_dir = \"/content/drive/MyDrive/\"\n",
        "base_dir = root_dir + \"tesi_magistrale/datasets/to_zip/\"\n",
        "path_corpus_data = root_dir + \"tesi_magistrale/datasets/corpus_data_folder/\"\n",
        "figer_path = base_dir + \"FIGER/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hm6RoPKn3IyB"
      },
      "source": [
        "import json\n",
        "\n",
        "with open(figer_path + \"train.json\", 'r') as inp:\n",
        "    examples_train = [json.loads(l) for l in inp.readlines()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-66bcSCfxoIo",
        "outputId": "57c93d32-819d-4460-ec28-2759e5f93f56"
      },
      "source": [
        "print(\"il dataset train contiene \",len(examples_train), \"elementi\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "il dataset train contiene  1505765 elementi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWJkJBNnBsXw"
      },
      "source": [
        "#ci sono 36 frasi che hanno le mentions vuote, le cancello\n",
        "indici = []\n",
        "for i,elem in enumerate(examples_train):\n",
        "  if len(elem['mentions'])==0:\n",
        "     indici.append(i)\n",
        "\n",
        "pop=0\n",
        "for num in indici:\n",
        "  del examples_train[num-pop]\n",
        "  pop+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkDsVLxg5M5k"
      },
      "source": [
        "entire_dataset_list = iter(examples_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4sMvJBQOm9e"
      },
      "source": [
        "lunghezze={\n",
        "    'minori=_10':0,\n",
        "    'maggiori_10_minori=_100':0,\n",
        "    'maggiori_100_minori=200':0,\n",
        "    'maggiori_200':0,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E80h-2ABJl6k",
        "outputId": "4ec80775-3742-443f-ff12-0f7a9d7b5e42"
      },
      "source": [
        "import operator\n",
        "import itertools\n",
        "from tqdm import tqdm\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "\n",
        "fp = open(path_corpus_data + 'corpus_data_entire_figer.txt', \"w\")\n",
        "restricted_set = set()\n",
        "mean=0\n",
        "for num,i in enumerate(tqdm(entire_dataset_list)):\n",
        "  \n",
        "  #calcolo le permutazioni in modo grossolano e skippo le frasi che genererebbero pi√π di 200 permutazioni\n",
        "  prod = 1\n",
        "  for elem in i['mentions']:\n",
        "    prod*=len(elem['labels'])\n",
        "\n",
        "  if prod<=10:\n",
        "    lunghezze['minori=_10']+=1\n",
        "  if prod>10 and  prod<=100:\n",
        "    lunghezze['maggiori_10_minori=_100']+=1\n",
        "  if prod>100 and prod<=200:\n",
        "    lunghezze['maggiori_100_minori=200']+=1\n",
        "  if (prod>200):\n",
        "    lunghezze['maggiori_200']+=1\n",
        "    continue\n",
        "\n",
        "  mean+=prod\n",
        "  istance = i['mentions'][:]\n",
        "  if len(istance)>1:\n",
        "    d = sorted(istance, key=operator.itemgetter(\"start\"))\n",
        "    d = {k: list(v) for k, v in itertools.groupby(d, key=operator.itemgetter(\"start\"))}\n",
        "    all_list=[]\n",
        "    for key, value in d.items():\n",
        "      all_list.append(value)\n",
        "\n",
        "    permutations = list(itertools.product(*all_list))\n",
        "\n",
        "    iter = 0\n",
        "    for p in permutations:\n",
        "          mini_list = []\n",
        "          for lista_labels in p:\n",
        "            mini_list.append(lista_labels['labels'])\n",
        "\n",
        "          permutations_2 = itertools.product(*mini_list)\n",
        "\n",
        "          for p_2 in permutations_2:\n",
        "            phrase = i['tokens'][:]\n",
        "            num_pop=0\n",
        "            for h in range(0, len(p_2)):\n",
        "              start = permutations[iter][h]['start']\n",
        "              end = permutations[iter][h]['end']\n",
        "              phrase[start-num_pop:end-num_pop] = [p_2[h]]\n",
        "              if ((end-start)>1):\n",
        "                num_pop += (end - start) - 1\n",
        "              restricted_set.add(p_2[h])\n",
        "\n",
        "            fp.write((remove_stopwords(' '.join(phrase)) + '\\n'))\n",
        "          iter+=1\n",
        "  else:\n",
        "    for k in istance[0]['labels']:\n",
        "      phrase = i['tokens'][:]\n",
        "      if (i['mentions'][0]['end'] - i['mentions'][0]['start'] ==1):          \n",
        "        phrase[i['mentions'][0]['start']] = k\n",
        "        restricted_set.add(k)\n",
        "      else:\n",
        "        phrase[i['mentions'][0]['start']:i['mentions'][0]['end']] = [k]\n",
        "        restricted_set.add(k)\n",
        "\n",
        "      fp.write((remove_stopwords(' '.join(phrase)) + '\\n'))\n",
        "\n",
        "fp.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1505729it [02:20, 10741.95it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YU52HrRiQz2E",
        "outputId": "091bc882-1cd7-48d2-fc83-889f2c6fc1ce"
      },
      "source": [
        "lunghezze"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'maggiori_100_minori=200': 12385,\n",
              " 'maggiori_10_minori=_100': 185841,\n",
              " 'maggiori_200': 20574,\n",
              " 'minori=_10': 1286929}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DXYQpHt_qRe",
        "outputId": "530c5b46-0419-41ab-e821-4c25193e4e44"
      },
      "source": [
        "print(f\"media permutazioni {mean/len(examples_train)} frasi skippate {lunghezze['maggiori_200']}, frasi processate {len(examples_train)-lunghezze['maggiori_200']}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "media permutazioni 7.282461850704874 frasi skippate 20574, frasi processate 1485155\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kf58neP0zEGL"
      },
      "source": [
        "restricted_list = list(restricted_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyXqWeAOzBga"
      },
      "source": [
        "import pickle\n",
        "with open(path_corpus_data + 'restricted_list_figer.pkl', 'wb') as fp:\n",
        "  pickle.dump(restricted_list, fp)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}