{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "entity_typing_data_parsing_BALANCED_ONTONOTES.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKL7Wwcj3pSj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1f90b9d-5f33-4474-89bd-eb2619800d11"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "root_dir = \"/content/drive/MyDrive/\"\n",
        "base_dir = root_dir + \"tesi_magistrale/datasets/to_zip/\"\n",
        "path_corpus_data = root_dir + \"tesi_magistrale/datasets/corpus_data_folder/\"\n",
        "balanced_ontonotes_path = base_dir + \"balanced_ontonotes/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hm6RoPKn3IyB"
      },
      "source": [
        "import json\n",
        "\n",
        "with open(balanced_ontonotes_path + \"train.json\", 'r') as inp:\n",
        "    examples_train = [json.loads(l) for l in inp.readlines()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-66bcSCfxoIo",
        "outputId": "621d3da7-3da7-4272-9675-2d41bf6858f3"
      },
      "source": [
        "print(\"il dataset train contiene \",len(examples_train), \"elementi\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "il dataset train contiene  249592 elementi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ns1R03kY2dKW",
        "outputId": "595f7e7d-31c1-4444-e5d8-b0b3e5bee85b"
      },
      "source": [
        "entire_dataset_list = examples_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " uniti train e test contengono  249592 elementi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mv7oiWh_RcM",
        "outputId": "4b3f813e-b40e-46a9-b1c5-18b8e5e35e3b"
      },
      "source": [
        "phrases = []\n",
        "for i in range (0,10):\n",
        "  if (len(entire_dataset_list[i]['y_str'])>1):\n",
        "    for k in range(0,len(entire_dataset_list[i]['y_str'])):\n",
        "      phrase = []\n",
        "      phrase = entire_dataset_list[i]['left_context_token'] + entire_dataset_list[i]['y_str'][k].upper().split() + entire_dataset_list[i]['right_context_token']\n",
        "      phrases.append(phrase)\n",
        "  else:\n",
        "    phrase = []\n",
        "    phrase = entire_dataset_list[i]['left_context_token'] + entire_dataset_list[i]['y_str'][0].upper().split() + entire_dataset_list[i]['right_context_token']\n",
        "    phrases.append(phrase)\n",
        "\n",
        "print(phrases)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['OK', ',', 'we', \"'ll\", 'call', 'him', 'General', '/PERSON', '.'], ['/PERSON/TITLE', 'that', 'was', ',', 'the', 'only', 'way', 'you', 'could', 'overcome', 'them', 'and', 'get', 'the', 'upper', 'hand', '.'], ['/PERSON', 'that', 'was', ',', 'the', 'only', 'way', 'you', 'could', 'overcome', 'them', 'and', 'get', 'the', 'upper', 'hand', '.'], ['Because', ',', 'there', 'was', 'no', 'way', ',', 'if', 'you', 'were', \"n't\", 'tough', 'that', 'was', 'it', ',', ',', 'how', 'could', 'you', '/PERSON/TITLE', '.'], ['Because', ',', 'there', 'was', 'no', 'way', ',', 'if', 'you', 'were', \"n't\", 'tough', 'that', 'was', 'it', ',', ',', 'how', 'could', 'you', '/PERSON', '.'], ['/PERSON/TITLE', 'you', 'picked', 'up', 'the', 'shovel', 'and', 'rushed', 'them', '.'], ['/PERSON', 'you', 'picked', 'up', 'the', 'shovel', 'and', 'rushed', 'them', '.'], ['All', 'of', 'a', 'sudden', 'nobody', 'was', 'making', 'a', '/PERSON/TITLE', '.'], ['All', 'of', 'a', 'sudden', 'nobody', 'was', 'making', 'a', '/PERSON', '.'], ['Nopbody', 'went', 'to', 'get', 'the', '/PERSON/TITLE', 'or', 'somebody', \"'s\", 'father', '?'], ['Nopbody', 'went', 'to', 'get', 'the', '/PERSON', 'or', 'somebody', \"'s\", 'father', '?'], ['I', 'remember', 'one', 'time', '--', 'Mm', ',', 'also', ',', 'when', 'I', 'was', 'in', 'fifth', 'or', 'sixth', 'grade', ',', 'someone', 'yelled', 'out', ',', 'Down', 'with', '/LOCATION', 'Zhengming', ',', 'he', 'was', 'yelling', 'at', 'me', ',', 'and', 'I', 'had', 'to', 'fight', 'them', '.'], [',', 'the', 'factory', ',', ',', 'on', 'the', 'street', ',', 'somebody', 'had', 'written', 'in', 'huge', 'letters', '/LOCATION', 'with', 'Ye', 'Zhengming', ',', ',', 'the', 'slogan', '.'], [',', 'the', 'factory', ',', ',', 'on', 'the', 'street', ',', 'somebody', 'had', 'written', 'in', 'huge', 'letters', 'Down', 'with', '/LOCATION', 'Zhengming', ',', ',', 'the', 'slogan', '.'], ['I', 'got', 'accustomed', 'to', 'it', 'while', 'passing', 'by', 'at', 'that', 'time', ',', 'and', 'now', 'when', 'I', 'think', 'about', 'it', ',', 'it', 'seems', 'very', 'much', 'like', 'a', '/PERSON/TITLE', 'play', '.'], ['I', 'got', 'accustomed', 'to', 'it', 'while', 'passing', 'by', 'at', 'that', 'time', ',', 'and', 'now', 'when', 'I', 'think', 'about', 'it', ',', 'it', 'seems', 'very', 'much', 'like', 'a', '/PERSON', 'play', '.']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODPmdXCyJP7Z"
      },
      "source": [
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "with open(path_corpus_data + \"corpus_data_balanced_ontonotes.txt\", \"w+\") as fp:\n",
        "  for p in phrases:\n",
        "    fp.write(' '.join(p) + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}