{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "analysis.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/francesco-mollica/word2vec-entity_embeddings/blob/main/analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNZExDcTWojg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67766da5-6104-4b19-cd52-84d737c51532"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "root_dir = \"/content/drive/MyDrive/\"\n",
        "base_dir = root_dir + \"tesi_magistrale/datasets/corpus_data_folder/\"\n",
        "base_dir_models = root_dir + \"tesi_magistrale/datasets/models_w2v/\""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0C92F9BWhoE"
      },
      "source": [
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vk6X4kLevPFq"
      },
      "source": [
        "custom_stopwords=True"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "li95kTSVoGEq"
      },
      "source": [
        "import json\n",
        "import operator\n",
        "dictionary_names= {1:\"choi\",2:\"balanced_ontonotes\",3:\"ontonotes\", 4:\"figer\", 5:\"bbn\"}\n",
        "\n",
        "dictionary_types_counters = {}\n",
        "# loading of types_counters dictionary\n",
        "for key, value in dictionary_names.items():\n",
        "  with open(base_dir + \"types_counters_\" + value + \".json\") as j:\n",
        "    dictionary_types_counters[value] = json.load(j)\n",
        "\n",
        "dictionary_models = {}\n",
        "# loading of normal models\n",
        "if custom_stopwords:\n",
        "  for key, value in dictionary_names.items():\n",
        "   dictionary_models [value]  = Word2Vec.load(base_dir_models + \"word2vec_\" + value + \"_custom.model\")\n",
        "else:\n",
        "  for key, value in dictionary_names.items():\n",
        "    dictionary_models [value]  = Word2Vec.load(base_dir_models + \"word2vec_\" + value + \".model\")\n",
        "    \n",
        "dictionary_restricted_models = {}\n",
        "# loading of restricted models\n",
        "if custom_stopwords:\n",
        "  for key, value in dictionary_names.items():\n",
        "    dictionary_restricted_models [value]  = Word2Vec.load(base_dir_models + \"word2vec_restricted_\" + value + \"_custom.model\")\n",
        "else:\n",
        "  for key, value in dictionary_names.items():\n",
        "    dictionary_restricted_models [value]  = Word2Vec.load(base_dir_models + \"word2vec_restricted_\" + value + \".model\")\n",
        "\n",
        "\n",
        "# loading of restricted list\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for key, value in dictionary_types_counters.items():\n",
        "  v = dict(sorted(value.items(), key=operator.itemgetter(1), reverse=True)[:10])\n",
        "  dictionary_types_counters[key] = v\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAI7iIk50yKH",
        "outputId": "b38419c7-b8d8-4015-f7a9-ec734369f43a"
      },
      "source": [
        "print(dictionary_types_counters)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'choi': {'/PERSON': 8240, '/ORGANIZATION': 2480, '/ADULT': 1940, '/LEADER': 1810, '/EVENT': 1810, '/MALE': 1670, '/OBJECT': 1600, '/PLACE': 1560, '/GROUP': 1520, '/LOCATION': 1310}, 'balanced_ontonotes': {'/OTHER': 91518, '/PERSON': 89224, '/LOCATION': 60203, '/ORGANIZATION': 43755, '/PERSON/TITLE': 37930, '/PERSON/ARTIST': 35310, '/PERSON/ARTIST/AUTHOR': 28876, '/LOCATION/COUNTRY': 22729, '/ORGANIZATION/COMPANY': 21554, '/PERSON/POLITICAL_FIGURE': 21376}, 'ontonotes': {'/OTHER': 92208, '/PERSON': 89531, '/LOCATION': 60583, '/ORGANIZATION': 44070, '/PERSON/TITLE': 37970, '/PERSON/ARTIST': 35496, '/PERSON/ARTIST/AUTHOR': 28998, '/LOCATION/COUNTRY': 22749, '/ORGANIZATION/COMPANY': 21680, '/PERSON/POLITICAL_FIGURE': 21455}, 'figer': {'/LOCATION': 1088112, '/PERSON': 726802, '/ORGANIZATION': 523689, '/LOCATION/CITY': 351151, '/PERSON/ARTIST': 255281, '/LOCATION/COUNTRY': 237732, '/PERSON/AUTHOR': 207806, '/PERSON/ACTOR': 180535, '/ORGANIZATION/COMPANY': 165610, '/EVENT': 143909}, 'bbn': {'/PERSON': 16704, '/ORGANIZATION': 13486, '/ORGANIZATION/CORPORATION': 10224, '/GPE': 6612, '/WORK_OF_ART': 4616, '/LOCATION': 4071, '/WORK_OF_ART/BOOK': 3493, '/SUBSTANCE': 3110, '/GPE/CITY': 3052, '/GPE/COUNTRY': 3020}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETiAZ3DuwB8Q"
      },
      "source": [
        "# prima analisi\n",
        "# per i 10 tipi pi첫 presenti in ciascun dataset quali sono le 10 parole pi첫 vicine\n",
        "for name, value in dictionary_types_counters.items():\n",
        "  print(name)\n",
        "  print(\"-----------\")\n",
        "  for typ, count in value.items():\n",
        "    print(\"prime 5 parole vicine a:\", typ)\n",
        "\n",
        "    contatore = 0\n",
        "    lista_results = dictionary_models[name].wv.most_similar(typ, topn = 500)\n",
        "    index = 0\n",
        "    while contatore <= 10:\n",
        "      if lista_results[index][0][0]!='/':\n",
        "        print(lista_results[index])\n",
        "        contatore+=1\n",
        "        index+=1\n",
        "      else:\n",
        "        index+=1\n",
        "\n",
        "         "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4cTFT7A09Bj"
      },
      "source": [
        "# seconda analisi\n",
        "# per i 10 tipi pi첫 presenti in ciascun dataset quali sono i 5 tipi pi첫 vicini\n",
        "for name, value in dictionary_types_counters.items():\n",
        "  print(name)\n",
        "  print(\"-----------\")\n",
        "  for typ, count in value.items():\n",
        "    print(\"prime 5 parole vicine a:\", typ)\n",
        "    print(dictionary_restricted_models[name].wv.most_similar(typ)[:5])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}